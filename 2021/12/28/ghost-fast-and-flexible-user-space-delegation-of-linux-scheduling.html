<!DOCTYPE html>
<html>
  <head>
    <script
      async
      src="https://www.googletagmanager.com/gtag/js?id=G-LKBDWTJ60B"
    ></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());

      gtag("config", "G-LKBDWTJ60B");
    </script>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
    <title>ghOSt: Fast & Flexible User-Space Delegation of Linux Scheduling</title>
    <meta
      name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no"
    />

    <meta http-equiv="pragma" content="no-cache" />
    <meta name="robots" content="all" />
    <meta name="MSSmartTagsPreventParsing" content="true" />
    <meta http-equiv="imagetoolbar" content="false" />

    <link href="/css/tufte.css" rel="stylesheet" />
    <link
      rel="alternate"
      type="application/atom+xml"
      title="Atom Feed for www.micahlerner.com"
      href="/atom.xml"
    />
    <link
      rel="alternate"
      type="application/atom+xml"
      title="RSS Feed for www.micahlerner.com"
      href="/feed.xml"
    />
    <link
      rel="apple-touch-icon"
      sizes="180x180"
      href="/assets/images/apple-touch-icon.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="32x32"
      href="/assets/images/favicon-32x32.png"
    />
    <link
      rel="icon"
      type="image/png"
      sizes="16x16"
      href="/assets/images/favicon-16x16.png"
    />
    <link rel="manifest" href="/assets/imagessite.webmanifest" />
  </head>

  <body>
    <article>
  <section>
    <header>
      <a href="/">
        <h3>micahlerner.com</h3>
      </a>
    </header>
  </section>
  <h1>ghOSt: Fast & Flexible User-Space Delegation of Linux Scheduling</h1>
  
  <h4>Published December 28, 2021</h4>
  <h5>
    Found something wrong?
    <a
      href="https://github.com/mlerner/mlerner.github.io/edit/master/_posts/2021-12-28-ghost-fast-and-flexible-user-space-delegation-of-linux-scheduling.md"
      >Submit a pull request!</a
    >
  </h5>
  <section id="post-content">
       <p class='discussion'>Discussion on <a href='https://news.ycombinator.com/item?id=30315716'> Hacker News</a></p>  
    <p>
      <em>
        This is one of the last papers I’m writing about from SOSP - I am trying out something new and publishing the queue of papers I plan on reading <a href="https://www.micahlerner.com/paper-queue">here</a>. These paper reviews can <a href="https://newsletter.micahlerner.com/">be delivered weekly to your inbox</a>, or you can subscribe to the <a href="https://www.micahlerner.com/feed.xml">Atom feed</a>. As always, feel free to reach out on <a href="https://twitter.com/micahlerner">Twitter</a> with feedback or suggestions!

        
      </em>
    </p>

     <p><a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/0ee589331b9bf270b13d40ba09453cde14006869.pdf">ghOSt: Fast &amp; Flexible User-Space Delegation of Linux Scheduling</a></p>

<p>The ghOSt paper describes a system for implementing Linux scheduling<label for="schedule" class="margin-toggle sidenote-number"></label><input type="checkbox" id="schedule" class="margin-toggle" /><span class="sidenote">This paper is about CPU scheduling, not data center scheduling (like I covered in a <a href="/2021/10/10/scaling-large-production-clusters-with-partitioned-synchronization.html">previous paper review</a>). </span> policies in user space<label for="userspace" class="margin-toggle sidenote-number"></label><input type="checkbox" id="userspace" class="margin-toggle" /><span class="sidenote">See <a href="https://unix.stackexchange.com/questions/87625/what-is-difference-between-user-space-and-kernel-space">What is difference between User space and Kernel space?</a>. </span>. Operating system scheduling is more complicated for data center workloads, as there are additional factors to consider when deciding what to run and when (like ensuring low latency for user queries). Previous research aims to take higher-level context about applications into consideration when making scheduling decisions<label for="shinjuku" class="margin-toggle sidenote-number"></label><input type="checkbox" id="shinjuku" class="margin-toggle" /><span class="sidenote">One example scheduler, <a href="https://www.usenix.org/conference/nsdi19/presentation/kaffes">Shinjuku</a>, is designed to reduce tail latency. The approach is able to achieve up to 6.6× higher throughput and 88% lower tail latency by implementing a custom scheduling policy. </span>, with dramatic positive results.</p>

<p>Unfortunately, custom schedulers can be difficult to implement, deploy, and maintain. <a href="https://www.usenix.org/conference/nsdi19/presentation/kaffes">Shinjuku</a> is an example<label for="caladan" class="margin-toggle sidenote-number"></label><input type="checkbox" id="caladan" class="margin-toggle" /><span class="sidenote">The paper also cites a set of Dune-themed projects, like <a href="https://www.usenix.org/system/files/osdi20-fried.pdf">Caladan</a> and <a href="https://www.usenix.org/system/files/nsdi19-ousterhout.pdf">Shenango</a> as prior work in the space that runs into the coupling problem. </span> of a custom scheduler facing these problems - it is designed to reduce tail latency for data center applications, but requires tight coupling between an application and the scheduler. This tight coupling means that changes to the kernel could also unintentionally impact applications using the approach, potentially causing a brittle implementation with high ongoing maintenance costs.</p>

<p>ghOSt aims to address the problems faced by custom schedulers and those who implement them, while facilitating the dramatic performance and scalability gains workload-specific schedulers allow. The key to its approach is separating scheduling logic and the components that interact with the kernel. Custom schedulers, called <em>policies</em>, are moved into user space.</p>

<p>In contrast, relatively stable code that interacts directly with the Linux kernel remains in kernel-space, and exposes an API for the user-space schedulers to interact with. This split approach means that custom schedulers run just like any other application - as a result, they can be implemented in variety of languages, tested using existing infrastructure, and deployed a faster rate for a wider set of workloads.</p>

<h2 id="what-are-the-papers-contributions">What are the paper’s contributions?</h2>

<p>The paper makes three main contributions: design and implementation of a system that allows custom scheduling logic to run in user space, implementations of several custom schedulers using the system, and evaluation of the architecture (including in a production setting).</p>

<h2 id="challenges-and-design-goals">Challenges and Design Goals</h2>

<p>The paper identifies five challenges to implementing custom schedulers:</p>

<ul>
  <li><em>Implementing schedulers is hard</em> because of the constraints posed on kernel code, like restrictions on languages<label for="rust" class="margin-toggle sidenote-number"></label><input type="checkbox" id="rust" class="margin-toggle" /><span class="sidenote">Support for <a href="https://github.com/Rust-for-Linux/linux">Rust</a> in the kernel is a work in progress. </span> and debug tooling<label for="kerneldebug" class="margin-toggle sidenote-number"></label><input type="checkbox" id="kerneldebug" class="margin-toggle" /><span class="sidenote">See a previous discussion on difficulties with kernel debugging on <a href="https://news.ycombinator.com/item?id=15952751">HN</a>. </span>.</li>
  <li><em>Deploying schedulers is even harder</em> because upgrading a kernel requires<label for="reboot" class="margin-toggle sidenote-number"></label><input type="checkbox" id="reboot" class="margin-toggle" /><span class="sidenote">Technically, not all changes to the kernel require a <a href="https://unix.stackexchange.com/questions/345561/how-linux-servers-update-their-kernel-without-rebooting">reboot</a>. </span> a time-consuming multi-step process of shifting workloads and rebooting the machine. The potential for kernel upgrades to introduce performance regressions make the process more difficult.</li>
  <li><em>Custom schedulers must schedule kernel-level threads</em>, not user-level threads<label for="userlevel" class="margin-toggle sidenote-number"></label><input type="checkbox" id="userlevel" class="margin-toggle" /><span class="sidenote">See <a href="https://stackoverflow.com/questions/15983872/difference-between-user-level-and-kernel-supported-threads">Difference between user-level and kernel-supported threads?</a>. </span> - scheduling user-level threads on top of kernel-level threads does not guarantee that the associated kernel-level threads are actually run<label for="devalts" class="margin-toggle sidenote-number"></label><input type="checkbox" id="devalts" class="margin-toggle" /><span class="sidenote">The paper notes two approaches that allow developers to overcome the limitations of user-level threads: “(1) Dedicate CPUs to the native threads running the user-threads, thus guaranteeing implicit control. However, this option wastes resources at low workload utilization, because the dedicated CPUs cannot be shared with another application (see §4.2), and requires extensive coordination around scaling capacity. Alternatively, developers can (2) stay at the mercy of the native thread scheduler, allowing CPUs to be shared, but ultimately losing the control over response time that they turned to a user-level runtime for.”  </span>.</li>
  <li><em>Custom schedulers tailored to specific workloads pose their own challenges</em> because they do not adapt well to different use cases (not to mention their internals are complex and potentially not shared across multiple schedulers).</li>
  <li><em>Existing custom scheduling techniques are not sufficient</em>, in particular Berkeley Packet Filter (BPF)<label for="bpf" class="margin-toggle sidenote-number"></label><input type="checkbox" id="bpf" class="margin-toggle" /><span class="sidenote">Julia Evans has a great post on <a href="https://jvns.ca/blog/2017/06/28/notes-on-bpf---ebpf/">BPF</a>, which was originally designed to capture and filter packets inside of the kernel. More recently, <a href="https://ebpf.io/">eBPF</a> extends the idea to other parts of the kernel - see <a href="https://lwn.net/Articles/740157/">A thorough introduction to eBPF</a> for more details on how BPF/eBPF works. There is also an exciting ecosystem building around eBPF tooling, like <a href="https://github.com/cilium/cilium">Cilium</a> and Isovalent, the company behind the tool, recently raised money from <a href="https://a16z.com/2020/11/10/investing-in-isovalent/">Andreessen Horowitz</a>. </span>. While BPF programs are amazingly cool, they run synchronously and block the CPU - non-ideal from a performance perspective<label for="fastpath" class="margin-toggle sidenote-number"></label><input type="checkbox" id="fastpath" class="margin-toggle" /><span class="sidenote">It is worth noting that the paper does mention using BPF for fast-path </span>.</li>
</ul>

<p>These challenges translate into four design goals for the system:</p>

<ul>
  <li><em>Custom scheduling logic should be easy to implement and test</em>: separating scheduling logic from the kernel simplifies development and testing.</li>
  <li><em>It should be possible to easily create scheduling logic for many different use cases</em>: unlike previous specialized schedulers built into the kernel, <em>ghOSt</em> aims to be a generic platform that schedulers can be built on top of.</li>
  <li><em>Scheduling should be able to operate across multiple CPUs</em>: existing Linux schedulers make per-CPU scheduling decisions and it is difficult to execute scheduling decisions over a set of CPUs to optimize for other properties, like tail latency<label for="taillatency" class="margin-toggle sidenote-number"></label><input type="checkbox" id="taillatency" class="margin-toggle" /><span class="sidenote">The paper cites a number of previous systems (like <a href="https://www.usenix.org/system/files/nsdi19-ousterhout.pdf">Shenango: Achieving high CPU efficiency for latency-sensitive datacenter workloads</a>) that achieve their goals by scheduling across multiple CPUs </span>.</li>
  <li><em>Non-disruptive updates and fault isolation</em>: it should be easy to deploy scheduling logic like one would with other tasks running on a machine, allowing updates without requiring a reboot. Furthermore, failures or regressions in scheduling policies should not crash the whole machine.</li>
</ul>

<h2 id="design-and-implementation">Design and Implementation</h2>

<p>To achieve the goals of the system, ghOSt introduces <em>policies</em> (custom scheduling logic). <em>Policies</em> are executed in user-space and associated scheduling decisions are communicated to the kernel.</p>

<figure><img class="maincolumn-img" src="/assets/ghost/arch.png" /><figcaption class="maincolumn-figure"></figcaption></figure>

<p>Policies (and their scheduling decisions) propagate over three main components running across kernel and user space:</p>

<ul>
  <li>The <em>ghOSt scheduling class</em><label for="scheduling class" class="margin-toggle sidenote-number"></label><input type="checkbox" id="scheduling class" class="margin-toggle" /><span class="sidenote">Here is a great article about scheduling classes and Linux’s <a href="https://developer.ibm.com/tutorials/l-completely-fair-scheduler/">Completely Fair Scheduler</a>. There is also the <a href="https://man7.org/linux/man-pages/man7/sched.7.html">man page</a> about the related <code class="language-plaintext highlighter-rouge">sched</code> system call. </span> runs inside of the Linux kernel and provides a syscall interface that other components use to communicate scheduling decisions.</li>
  <li><em>Agents</em> run <em>policies</em> (custom scheduling logic) in user-space, and make scheduling decisions that they communicate to the <em>ghOSt scheduling class</em> running in kernel-space.</li>
  <li><em>Enclaves</em> are groups of <em>agents</em>. Each <em>enclave</em> has a primary agent that makes the scheduling decisions. Assigning multiple <em>agents</em> to an enclave provides redundancy in the case of the primary agent failing.</li>
</ul>

<figure><img class="maincolumn-img" src="/assets/ghost/enclaves.png" /><figcaption class="maincolumn-figure"></figcaption></figure>

<h3 id="communication">Communication</h3>

<p><em>ghOSt</em> components running in kernel or user-space need a way to provide information and feedback to each other. The paper discusses the two primary communication flows: <em>kernel-to-agent</em> and <em>agent-to-kernel</em>.</p>

<figure><img class="maincolumn-img" src="/assets/ghost/messages.png" /><figcaption class="maincolumn-figure"></figcaption></figure>

<p>In the <em>kernel-to-agent</em> flow, the <em>kernel</em> communicates to <em>agents</em> using messages and message queues<label for="msg" class="margin-toggle sidenote-number"></label><input type="checkbox" id="msg" class="margin-toggle" /><span class="sidenote">Definition of the messages <a href="https://github.com/google/ghost-userspace/blob/d3f7b075e3619538ae5b758ec728a40cc0c42bd3/kernel/ghost_uapi.h#L81">here</a>. </span>. The kernel sends messages on queues when events happen in the kernel that could impact scheduling decisions. Each CPU has an associated queue, and each queue is associated with an enclave<label for="msgenclave" class="margin-toggle sidenote-number"></label><input type="checkbox" id="msgenclave" class="margin-toggle" /><span class="sidenote">Not every agent has a message queue because in some configurations there is a single primary agent for the enclave that is receiving information from the kernel - reference the enclave diagram above for a visual representation of this idea. </span>. While there are several existing queue approaches (including <a href="https://lwn.net/Articles/810414/">io_uring</a> or <a href="https://nakryiko.com/posts/bpf-ringbuf/">BPF ring buffers</a>), not all kernel versions support them - the authors argue that this makes ghOSt’s queue abstraction necessary.</p>

<p>In the <em>agent-to-kernel</em> direction, the <em>agent</em> communicates by making system calls to communicate scheduling decisions and to perform management operations on the shared queue. To send scheduling decisions, the <em>agent</em> creates and commits transactions (like <code class="language-plaintext highlighter-rouge">TXN_CREATE()</code> and <code class="language-plaintext highlighter-rouge">TXNS_COMMIT()</code>). Transactions are important because they allow a policy to make scheduling decisions across a range of CPUs, ensuring all or none succeed, while batching scheduling information - batching is critical because it limits the number of interrupts that impact the to-be-scheduled CPUs (as the kernel component of ghOSt needs to respond to agent transactions).</p>

<p>Lastly, there is a challenge to both <em>kernel-to-agent</em> and <em>agent-to-kernel</em> communication: keeping up to date with the state of the system. The kernel needs to ensure that it doesn’t execute out of date scheduling decisions, and the agent need to make sure that it doesn’t make scheduling decisions based on an old state of the world. The key piece of information used to track state is a <em>sequence number</em> that exists for every agent.</p>

<p>In <em>kernel-to-agent</em> commmunication, the kernel provides the <em>sequence number</em> to agents in each message, and in a shared memory region. The sequence number in shared memory is updated by the kernel whenever it publishes a new message. The agent consumes the <em>sequence number</em> from shared memory when reading messages from the queue, comparing the value to the <em>sequence number</em> in shared memory. When the sequence number from consumed messages matches the value in shared memory, the agent knows it has read an up to date state.</p>

<p>In <em>agent-to-kernel</em> communication, the agent includes the <em>sequence number</em> when sending scheduling decisions (via transactions) to the kernel. The kernel compares the <em>sequence number</em> from the agent’s transaction with the most recent sequence number the kernel is aware of. If the transaction’s sequence number is too old, the kernel doesn’t execute the scheduling decision.</p>

<h2 id="evaluation">Evaluation</h2>

<p>To evaluate ghOSt, the paper considers the overheads associated with the system, compares ghOSt to previous custom scheduler implementations, and evaluates the system in production.</p>

<h3 id="ghost-overhead">ghOSt overhead</h3>

<p>To evaluate the overheads of the system, the paper includes microbenchmarks that show the time spent in the different parts of the scheduling system, showing that it is competitive.</p>

<figure><img class="maincolumn-img" src="/assets/ghost/microbenchmark.png" /><figcaption class="maincolumn-figure"></figcaption></figure>

<p>The paper also determines the performance of a global scheduler (that schedules all cores on a system) implemented with ghOSt - previous research shows the potential advantage of this approach as the scheduler has more complete knowledge of the system. The evaluation shows that ghOSt is able to scale to millions of transactions, even when responsible for many CPUs.</p>

<figure><img class="maincolumn-img" src="/assets/ghost/global.png" /><figcaption class="maincolumn-figure"></figcaption></figure>

<h3 id="comparison-to-existing-systems">Comparison to existing systems</h3>

<p>Next, the paper compares ghOSt to Shinjuku<label for="shinjukucomp" class="margin-toggle sidenote-number"></label><input type="checkbox" id="shinjukucomp" class="margin-toggle" /><span class="sidenote">See the <a href="https://www.usenix.org/conference/nsdi19/presentation/kaffes">Shinjuku</a> paper. </span>, an example of a custom scheduling system tailored to reduce tail latency. The goal of this evaluation is to see whether <em>ghOSt</em> performs similarly to a custom scheduler (which theoretically could achieve higher performance by using tailored optimization techniques). Shinjuku has a number of differences from <em>ghOSt</em> - it uses dedicated resources (spinning threads that consume all of a CPU or set of CPUs), is constrained to a physical set of cores, and takes advantage of virtualization features to increase performance (like <a href="https://xenbits.xen.org/docs/4.9-testing/misc/vtd-pi.txt">posted interrupts</a>). The authors also port the Shinjuku scheduling policy itself so that it is compatible with ghOSt.</p>

<p>The two systems run a generated workload, “in which each request includes a GET query to an in-memory RocksDB key-value store and performs a small amount of processing”.</p>

<p>The results indicate:</p>

<blockquote>
  <p>ghOSt is competitive with Shinjuku for 𝜇s-scale tail workloads, even though its Shinjuku policy is implemented in 82% fewer lines of code than the custom Shinjuku data plane system. ghOSt has slightly higher tail latencies than Shinjuku at high loads and is within 5% of Shinjuku’s saturation throughput.</p>
</blockquote>

<figure><img class="maincolumn-img" src="/assets/ghost/shinjuku.png" /><figcaption class="maincolumn-figure"></figcaption></figure>

<h3 id="production-traces">Production traces</h3>

<p>Lastly, the paper runs a production workload against ghOSt and compares the results to the same workload executed by machines using the completely fair scheduler (CFS)<label for="cfs" class="margin-toggle sidenote-number"></label><input type="checkbox" id="cfs" class="margin-toggle" /><span class="sidenote">More info on the Completely Fair Scheduler <a href="https://developer.ibm.com/tutorials/l-completely-fair-scheduler/">here</a> - on the older side, but seems like it was updated relatively recently. </span>.</p>

<p>The workload contains three query types (CPU and memory bound, IO and memory bound, and CPU-bound) - ghOSt is able to reduce tail-latency for the first two types of requests, but doesn’t have a huge impact for the third<label for="third" class="margin-toggle sidenote-number"></label><input type="checkbox" id="third" class="margin-toggle" /><span class="sidenote">The paper does note that it is possible to impact compute bound tasks by extending the ghOSt policy with similar logic to what Linux’s CFS contains around <code class="language-plaintext highlighter-rouge">nice</code> values. </span>.</p>

<p>What stood out to me the most about this section is actually ghOSt’s impact on developer productivity:</p>

<blockquote>
  <p>When developing a kernel scheduler, the write-test-write cycle includes (a) compiling a kernel (up to 15 minutes), (b) deploying the kernel (10-20 minutes), and (c) running the test (1 hour due to database initialization following a reboot). As a result, the enthusiastic kernel developer experiments with 5 variants per day. With ghOSt, compiling, deploying and launching the new agent is comfortably done within one minute.</p>
</blockquote>

<h2 id="conclusion">Conclusion</h2>

<p>The ghOSt paper builds on a body of previous research that demonstrates how critical scheduling is to the scalability and performance of datacenter workloads.  Scheduling is far from a solved problem, especially because of the “rise of the killer microsecond” and new device types - I’m looking forward to following along future work on the <a href="https://github.com/google/ghost-userspace">ghOSt open source project</a>!</p>

<p>As always, feel free to reach out on <a href="https://twitter.com/micahlerner">Twitter</a> with feedback. Until next time.</p>


    <footer>
      <form
        action="https://gmail.us20.list-manage.com/subscribe/post?u=d1654f70a6addb0e9ce8afd83&amp;id=bab65ed2b1"
        method="post"
        id="mc-embedded-subscribe-form"
        name="mc-embedded-subscribe-form"
        class="validate"
        target="_blank"
        novalidate
      >
        <div id="mc_embed_signup_scroll">
          <h4>
            Follow me on
            <a href="https://twitter.com/micahlerner">Twitter</a> or subscribe
            below to get future paper reviews. Published weekly.
          </h4>
          <div>
            <input
              type="email"
              value=""
              name="EMAIL"
              class="email"
              id="tlemail"
              placeholder="email address"
              required
            />
            <!-- real people should not fill this in and expect good things - do not remove this or risk form bot signups-->
            <div style="position: absolute; left: -5000px" aria-hidden="true">
              <input
                type="text"
                name="b_d1654f70a6addb0e9ce8afd83_bab65ed2b1"
                tabindex="-1"
                value=""
              />
            </div>
            <input
              type="submit"
              value="Subscribe"
              name="subscribe"
              id="mc-embedded-subscribe"
              class="button"
            />
          </div>
        </div>
      </form>
    </footer>
  </section>
  <section>
    Found something wrong?
    <a
      href="https://github.com/mlerner/mlerner.github.io/edit/master/_posts/2021-12-28-ghost-fast-and-flexible-user-space-delegation-of-linux-scheduling.md"
      >Submit a pull request!</a
    >
  </section>
</article>

<div id="portal-root">
  <div id="subscribe-container">
    <div id="gh-portal-triggerbtn-wrapper" class="gh-portal-triggerbtn-wrapper">
      <div class="gh-portal-triggerbtn-container with-label">
        <svg
          width="24"
          height="18"
          viewBox="0 0 24 18"
          fill="none"
          xmlns="http://www.w3.org/2000/svg"
          style="width: 24px; height: 24px; color: rgb(255, 255, 255)"
        >
          <path
            d="M21.75 1.5H2.25c-.828 0-1.5.672-1.5 1.5v12c0 .828.672 1.5 1.5 1.5h19.5c.828 0 1.5-.672 1.5-1.5V3c0-.828-.672-1.5-1.5-1.5zM15.687 6.975L19.5 10.5M8.313 6.975L4.5 10.5"
            stroke="#fff"
            stroke-width="1.5"
            stroke-linecap="round"
            stroke-linejoin="round"
          ></path>
          <path
            d="M22.88 2.014l-9.513 6.56C12.965 8.851 12.488 9 12 9s-.965-.149-1.367-.426L1.12 2.014"
            stroke="#fff"
            stroke-width="1.5"
            stroke-linecap="round"
            stroke-linejoin="round"
          ></path></svg
        ><span class="gh-portal-triggerbtn-label"> Subscribe </span>
      </div>
    </div>
  </div>
</div>

<div id="popup-root" style="visibility: hidden">
  <div class="inner-popup-container">
    <div class="gh-portal-popup-background"></div>
    <div class="gh-portal-popup-wrapper signup">
      <div
        class="gh-portal-popup-container gh-portal-container-narrow signup"
        tabindex="-1"
      >
        <div class="gh-portal-content signup noplan">
          <div id="closeicon-email" class="gh-portal-closeicon-container">
            <svg
              xmlns="http://www.w3.org/2000/svg"
              viewBox="0 0 24 24"
              class="gh-portal-closeicon"
              alt="Close"
            >
              <defs>
                <style>
                  .a {
                    fill: none;
                    stroke: currentColor;
                    stroke-linecap: round;
                    stroke-linejoin: round;
                    stroke-width: 1.2px;
                  }
                </style>
              </defs>
              <path
                class="a"
                d="M.75 23.249l22.5-22.5M23.25 23.249L.75.749"
              ></path>
            </svg>
          </div>
          <header>
            <h2 class="gh-portal-main-title">Get essays a bit faster</h2>
          </header>
          <section>
            <div class="gh-portal-section">
              <form
                action="https://gmail.us20.list-manage.com/subscribe/post?u=d1654f70a6addb0e9ce8afd83&amp;id=bab65ed2b1"
                method="post"
                id="mc-embedded-subscribe-form"
                name="mc-embedded-subscribe-form"
                class="validate"
                target="_blank"
                novalidate=""
                _lpchecked="1"
              >
                <label for="mce-EMAIL"> </label>
                <p id="mce-email-describe" class="mt0">
                  I write about computer science research from the fields of
                  distributed systems and operating systems around once a week.
                </p>
                <p></p>
                <div id="mc_embed_signup_scroll">
                  <div>
                    <input
                      type="email"
                      value=""
                      name="EMAIL"
                      class="email"
                      id="tlemail"
                      placeholder="email address"
                      required=""
                    />

                    <div
                      style="position: absolute; left: -5000px"
                      aria-hidden="true"
                    >
                      <input
                        type="text"
                        name="b_d1654f70a6addb0e9ce8afd83_bab65ed2b1"
                        tabindex="-1"
                        value=""
                      />
                    </div>
                    <input
                      type="submit"
                      value="Subscribe"
                      name="subscribe"
                      id="mc-embedded-subscribe"
                      class="button"
                    />
                  </div>
                </div>
              </form>
            </div>
          </section>
        </div>
      </div>
    </div>
  </div>
</div>

<script id="mcjs">
  var subscribeButton = document.getElementById("gh-portal-triggerbtn-wrapper");
  var closeButton = document.getElementById("closeicon-email");
  var popupRoot = document.getElementById("popup-root");

  subscribeButton.addEventListener("click", function () {
    window.open('https://newsletter.micahlerner.com', '_blank');
    <!-- popupRoot.classList.toggle("m-fadeIn"); -->
    <!-- popupRoot.style.visibility = "visible"; -->
  });

  closeButton.addEventListener("click", function () {
    <!-- popupRoot.classList.toggle("m-fadeOut"); -->
    <!-- popupRoot.classList.toggle("m-fadeIn"); -->
    <!-- popupRoot.style.visibility = "hidden"; -->
  });
</script>

  </body>
</html>
